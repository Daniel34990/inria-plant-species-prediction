{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, data_dir, metadata, subset, transform=None):\n",
    "        self.subset = subset  # Type de sous-ensemble (ex: train, val, test)\n",
    "        self.transform = transform  # Transformation à appliquer aux échantillons\n",
    "        self.data_dir = data_dir  # Répertoire contenant les fichiers de données\n",
    "        self.metadata = metadata  # Données de métadonnées\n",
    "        # Supprimer les lignes sans speciesId et réinitialiser les index\n",
    "        self.metadata = self.metadata.dropna(subset=[\"speciesId\"]).reset_index(drop=True)\n",
    "        self.metadata['speciesId'] = self.metadata['speciesId'].astype(int)  # Convertir speciesId en entier\n",
    "        \n",
    "        self.label_dict = self.metadata.groupby('surveyId')['speciesId'].apply(list).to_dict()\n",
    "        self.presence_dict = self.metadata.groupby(['surveyId', 'speciesId'])['presence'].first().to_dict()\n",
    "        \n",
    "        self.metadata = self.metadata.drop_duplicates(subset=\"surveyId\").reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        # Retourne le nombre de surveyId uniques\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        survey_id = self.metadata.surveyId[idx]\n",
    "        sample = torch.nan_to_num(torch.load(os.path.join(self.data_dir, f\"GLC24-PA-{self.subset}-landsat-time-series_{survey_id}_cube.pt\")))\n",
    "        species_ids = self.label_dict.get(survey_id, [])  # Obtenir la liste des species IDs pour le survey ID\n",
    "        label = torch.zeros(num_classes)  \n",
    "        for species_id in species_ids:\n",
    "            label[species_id] = self.presence_dict.get((survey_id, species_id), 0.0)\n",
    "\n",
    "        # Assurer que l'échantillon est dans le bon format pour la transformation\n",
    "        if isinstance(sample, torch.Tensor):\n",
    "            sample = sample.permute(1, 2, 0)  # Changer la forme du tenseur de (C, H, W) à (H, W, C)\n",
    "            sample = sample.numpy()  \n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample, label, survey_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "985\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "num_classes = 11255\n",
    "#Load Training metadata\n",
    "train_data_path = \"/home/dakbarin/data/data/GEOLIFECLEF/GLC24-PA-train-landsat-time-series\"\n",
    "train_metadata_path = \"/home/dakbarin/data/data/GEOLIFECLEF/metadata_for_presence_all.csv\"\n",
    "train_metadata = pd.read_csv(train_metadata_path)\n",
    "train_dataset = TrainDataset(train_data_path, train_metadata, subset=\"train\", transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=16)\n",
    "\n",
    "test_data_path = \"/home/dakbarin/data/data/GEOLIFECLEF/GLC24-PA-train-landsat-time-series\"\n",
    "test_metadata_path = \"/home/dakbarin/data/data/GEOLIFECLEF/metadata_for_presence_all.csv\"\n",
    "test_metadata = pd.read_csv(train_metadata_path)\n",
    "test_dataset = TrainDataset(test_data_path, test_metadata, subset=\"train\", transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "print(len(train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedResNet18(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ModifiedResNet18, self).__init__()\n",
    "\n",
    "        self.norm_input = nn.LayerNorm([6,4,21])\n",
    "        self.resnet18 = models.resnet18(weights=None)\n",
    "        # We have to modify the first convolutional layer to accept 4 channels instead of 3\n",
    "        self.resnet18.conv1 = nn.Conv2d(6, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.resnet18.maxpool = nn.Identity()\n",
    "        self.ln = nn.LayerNorm(1000)\n",
    "        self.fc1 = nn.Linear(1000, 2056)\n",
    "        self.fc2 = nn.Linear(2056, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm_input(x)\n",
    "        x = self.resnet18(x)\n",
    "        x = self.ln(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE = CUDA\n"
     ]
    }
   ],
   "source": [
    "# Check if cuda is available\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"DEVICE = CUDA\")\n",
    "\n",
    "num_classes = 11255 # Number of all unique classes within the PO and PA data.\n",
    "model = ModifiedResNet18(num_classes).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dakbarin/.local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.0002\n",
    "num_epochs = 20\n",
    "positive_weigh_factor = 1.0\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 20 epochs started.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1263083f246a43539409f7f794eb4050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/20:   0%|          | 0/985 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Batch 0/985, Loss: 0.7045856714248657\n",
      "Epoch 1/20, Batch 278/985, Loss: 0.011697283945977688\n",
      "Epoch 1/20, Batch 556/985, Loss: 0.012349762953817844\n",
      "Epoch 1/20, Batch 834/985, Loss: 0.011131570674479008\n",
      "Scheduler: {'T_max': 25, 'eta_min': 0, 'base_lrs': [0.0002], 'last_epoch': 1, 'verbose': True, '_step_count': 2, '_get_lr_called_within_step': False, '_last_lr': [0.0001992114701314478]}\n",
      "Epoch 1 completed in 52.03 seconds.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23846be5fa140ccb038ae628187587e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/20:   0%|          | 0/985 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Batch 0/985, Loss: 0.011535607278347015\n",
      "Epoch 2/20, Batch 278/985, Loss: 0.010793199762701988\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_38892/2861455091.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "print(f\"Training for {num_epochs} epochs started.\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()  # Start the timer for this epoch\n",
    "    \n",
    "    model.train()\n",
    "    # Wrap the train_loader with tqdm\n",
    "    for batch_idx, (data, targets, _) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")):\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "\n",
    "        pos_weight = targets * positive_weigh_factor  # All positive weights are equal to 10\n",
    "        criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 278 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item()}\")\n",
    "\n",
    "    scheduler.step()\n",
    "    print(\"Scheduler:\", scheduler.state_dict())\n",
    "\n",
    "    end_time = time.time()  # Stop the timer for this epoch\n",
    "    epoch_duration = end_time - start_time\n",
    "    print(f\"Epoch {epoch+1} completed in {epoch_duration:.2f} seconds.\")\n",
    "\n",
    "# Save the trained model\n",
    "model.eval()\n",
    "torch.save(model.state_dict(), \"resnet18-with-bioclimatic-cubes3.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_species = 11255\n",
    "batch_size = 64\n",
    "device = 'cuda'\n",
    "def remove_module_prefix(state_dict):\n",
    "    new_state_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "        if k.startswith('module.'):\n",
    "            new_state_dict[k[7:]] = v\n",
    "        else:\n",
    "            new_state_dict[k] = v\n",
    "    return new_state_dict\n",
    "\n",
    "# Charger l'état du modèle entraîné\n",
    "model = ModifiedResNet18(num_species).to(device)\n",
    "state_dict = torch.load(\"/home/dakbarin/data/models/resnet18_with_bioclimatic_cubes_epoch_16.pth\")\n",
    "state_dict = remove_module_prefix(state_dict)\n",
    "model.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_298752/2463850170.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Calculer le F1 score micro\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mf1_micro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'micro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"F1 Score Micro: {f1_micro}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.66666667\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m        \u001b[0;34m,\u001b[0m \u001b[0;36m0.66666667\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \"\"\"\n\u001b[0;32m-> 1132\u001b[0;31m     return fbeta_score(\n\u001b[0m\u001b[1;32m   1133\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1268\u001b[0m     \"\"\"\n\u001b[1;32m   1269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m     _, _, f, _ = precision_recall_fscore_support(\n\u001b[0m\u001b[1;32m   1271\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1554\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1556\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1558\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1355\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"average has to be one of \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1357\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1358\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m     \u001b[0;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[1;32m     84\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be class 'SparseSeries' or 'SparseArray'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_multilabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mis_multilabel\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    171\u001b[0m         )\n\u001b[1;32m    172\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         return len(labels) < 3 and (\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/misc/opt/conda3-2021.11/lib/python3.9/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/misc/opt/conda3-2021.11/lib/python3.9/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mFind\u001b[0m \u001b[0mthe\u001b[0m \u001b[0munique\u001b[0m \u001b[0melements\u001b[0m \u001b[0mof\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignoring\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \"\"\"\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0moptional_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_index\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#odel = ModifiedResNet18(num_classes).to(device)\n",
    "#state_dict = torch.load(\"/home/dakbarin/data/models/resnet18-with-bioclimatic-cubes3.pth\")\n",
    "#model.load_state_dict(state_dict)\n",
    "\n",
    "def test_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels, _ = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Transférer les données sur le même dispositif\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.sigmoid(outputs)  # Utiliser la fonction sigmoid pour obtenir des probabilités\n",
    "            \n",
    "            # Convertir les prédictions et les labels en valeurs binaires\n",
    "            preds_binary = (preds > 0.5).int()\n",
    "            \n",
    "            all_preds.append(preds_binary.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    \n",
    "    return np.concatenate(all_preds), np.concatenate(all_labels)\n",
    "\n",
    "# Tester le modèle\n",
    "preds, labels = test_model(model, test_loader, device)\n",
    "\n",
    "preds = preds.astype(int)\n",
    "labels = labels.astype(int)\n",
    "\n",
    "# Calculer le F1 score micro\n",
    "f1_micro = f1_score(labels, preds, average='micro')\n",
    "print(f\"F1 Score Micro: {f1_micro}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(TrainDataset):\n",
    "    def __init__(self, data_dir, metadata, subset, transform=None):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "        self.data_dir = data_dir\n",
    "        self.metadata = metadata\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        survey_id = self.metadata.surveyId[idx]\n",
    "        sample = torch.nan_to_num(torch.load(os.path.join(self.data_dir, f\"GLC24-PA-{self.subset}-landsat_time_series_{survey_id}_cube.pt\")))\n",
    "\n",
    "        if isinstance(sample, torch.Tensor):\n",
    "            sample = sample.permute(1, 2, 0)  # Change tensor shape from (C, H, W) to (H, W, C)\n",
    "            sample = sample.numpy()\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample, survey_id\n",
    "    \n",
    "# Load Test metadata\n",
    "test_data_path = \"/home/dakbarin/data/data/GEOLIFECLEF/GLC24-PA-test-landsat_time_series\"\n",
    "test_metadata_path = \"/home/dakbarin/data/data/GEOLIFECLEF/GLC24-PA-metadata-test.csv\"\n",
    "test_metadata = pd.read_csv(test_metadata_path, delimiter =';')\n",
    "test_dataset = TestDataset(test_data_path, test_metadata, subset=\"test\", transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "669b77f29c6d4f3a8433f90ccd035b27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "\n",
    "with torch.no_grad():\n",
    "    all_preds = []\n",
    "    surveys = []\n",
    "    for data, surveyID in tqdm(test_loader, total=len(test_loader)):\n",
    "        data = data.to(device)\n",
    "        predictions = model(data)\n",
    "        \n",
    "        preds = torch.sigmoid(predictions)  # Appliquer sigmoid avant la conversion en numpy\n",
    "        preds_binary = (preds > 0.9).int()\n",
    "        \n",
    "        all_preds.append(preds_binary.cpu().numpy())\n",
    "        surveys.extend(surveyID.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12cef2bdf05446d999d7871904c99796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0020326113\n",
      "0.0012975612\n",
      "0.002156962\n",
      "0.001861093\n",
      "0.0018279508\n",
      "0.002208804\n",
      "0.0013880328\n",
      "0.0021042519\n",
      "0.0013884115\n",
      "0.0017737538\n",
      "0.0014538981\n",
      "5.0315593e-05\n",
      "0.0027619451\n",
      "0.0013386263\n",
      "0.0015388025\n",
      "0.0024310711\n",
      "0.0031582278\n",
      "0.001251995\n",
      "0.0011549818\n",
      "0.0015126732\n",
      "0.002023811\n",
      "0.001910845\n",
      "0.0017412904\n",
      "0.0022508393\n",
      "0.0019879558\n",
      "0.0024842292\n",
      "0.00097367127\n",
      "0.0008113582\n",
      "0.0017538437\n",
      "0.0009668477\n",
      "0.0016370277\n",
      "0.0022209045\n",
      "0.0016761761\n",
      "0.0002811433\n",
      "0.0018631986\n",
      "0.0007181519\n",
      "0.0015413117\n",
      "0.0020072258\n",
      "0.0025743723\n",
      "0.0016864135\n",
      "0.0020383\n",
      "0.0019478108\n",
      "0.0021896085\n",
      "0.0010005254\n",
      "0.0016190639\n",
      "0.0015712319\n",
      "0.001437789\n",
      "0.0031574876\n",
      "0.0023934497\n",
      "0.00076946785\n",
      "0.004016435\n",
      "0.0007154298\n",
      "0.0019806686\n",
      "0.0010469322\n",
      "0.0009526873\n",
      "0.0008430004\n",
      "0.0013295043\n",
      "0.002196231\n",
      "0.0012516696\n",
      "0.0014193463\n",
      "0.00039052436\n",
      "0.0006419512\n",
      "0.0009329487\n",
      "0.002703704\n",
      "0.0019057964\n",
      "0.0015103264\n",
      "0.0018504629\n",
      "0.0023980765\n",
      "0.0014161653\n",
      "0.0022701996\n",
      "0.0015969276\n",
      "0.0029920165\n",
      "0.002217706\n",
      "0.002770718\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    all_predictions = []\n",
    "    surveys = []\n",
    "    top_k_indices = None\n",
    "    for data, surveyID in tqdm(test_loader, total=len(test_loader)):\n",
    "\n",
    "        data = data.to(device)\n",
    "        predictions = model(data)\n",
    "        predictions = torch.sigmoid(predictions).cpu().numpy()\n",
    "        print(predictions[0,642])\n",
    "\n",
    "        # Sellect top-25 values as predictions\n",
    "        top_25 = np.argsort(-predictions, axis=1)[:, :500] \n",
    "        if top_k_indices is None:\n",
    "            top_k_indices = top_25\n",
    "        else:\n",
    "            top_k_indices = np.concatenate((top_k_indices, top_25), axis=0)\n",
    "\n",
    "        surveys.extend(surveyID.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n",
      "4716\n"
     ]
    }
   ],
   "source": [
    "print(len(all_preds))\n",
    "print(len(surveys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_concatenated = [' '.join(map(str, row)) for row in top_k_indices]\n",
    "\n",
    "pd.DataFrame(\n",
    "    {'surveyId': surveys,\n",
    "     'predictions': data_concatenated,\n",
    "    }).to_csv(\"submission.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
